<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-57W8FQPR');
  </script>
  <!-- End Google Tag Manager -->

  <!-- Start VWO Async SmartCode -->
  <link rel="preconnect" href="https://dev.visualwebsiteoptimizer.com" />
  <script type='text/javascript' id='vwoCode'>
  window._vwo_code || (function() {
  var account_id=1082301,
  version=2.1,
  settings_tolerance=2000,
  hide_element='body',
  hide_element_style = 'opacity:0 !important;filter:alpha(opacity=0) !important;background:none !important;transition:none !important;',
  /* DO NOT EDIT BELOW THIS LINE */
  f=false,w=window,d=document,v=d.querySelector('#vwoCode'),cK='_vwo_'+account_id+'_settings',cc={};try{var c=JSON.parse(localStorage.getItem('_vwo_'+account_id+'_config'));cc=c&&typeof c==='object'?c:{}}catch(e){}var stT=cc.stT==='session'?w.sessionStorage:w.localStorage;code={nonce:v&&v.nonce,use_existing_jquery:function(){return typeof use_existing_jquery!=='undefined'?use_existing_jquery:undefined},library_tolerance:function(){return typeof library_tolerance!=='undefined'?library_tolerance:undefined},settings_tolerance:function(){return cc.sT||settings_tolerance},hide_element_style:function(){return'{'+(cc.hES||hide_element_style)+'}'},hide_element:function(){if(performance.getEntriesByName('first-contentful-paint')[0]){return''}return typeof cc.hE==='string'?cc.hE:hide_element},getVersion:function(){return version},finish:function(e){if(!f){f=true;var t=d.getElementById('_vis_opt_path_hides');if(t)t.parentNode.removeChild(t);if(e)(new Image).src='https://dev.visualwebsiteoptimizer.com/ee.gif?a='+account_id+e}},finished:function(){return f},addScript:function(e){var t=d.createElement('script');t.type='text/javascript';if(e.src){t.src=e.src}else{t.text=e.text}v&&t.setAttribute('nonce',v.nonce);d.getElementsByTagName('head')[0].appendChild(t)},load:function(e,t){var n=this.getSettings(),i=d.createElement('script'),r=this;t=t||{};if(n){i.textContent=n;d.getElementsByTagName('head')[0].appendChild(i);if(!w.VWO||VWO.caE){stT.removeItem(cK);r.load(e)}}else{var o=new XMLHttpRequest;o.open('GET',e,true);o.withCredentials=!t.dSC;o.responseType=t.responseType||'text';o.onload=function(){if(t.onloadCb){return t.onloadCb(o,e)}if(o.status===200||o.status===304){_vwo_code.addScript({text:o.responseText})}else{_vwo_code.finish('&e=loading_failure:'+e)}};o.onerror=function(){if(t.onerrorCb){return t.onerrorCb(e)}_vwo_code.finish('&e=loading_failure:'+e)};o.send()}},getSettings:function(){try{var e=stT.getItem(cK);if(!e){return}e=JSON.parse(e);if(Date.now()>e.e){stT.removeItem(cK);return}return e.s}catch(e){return}},init:function(){if(d.URL.indexOf('__vwo_disable__')>-1)return;var e=this.settings_tolerance();w._vwo_settings_timer=setTimeout(function(){_vwo_code.finish();stT.removeItem(cK)},e);var t;if(this.hide_element()!=='body'){t=d.createElement('style');var n=this.hide_element(),i=n?n+this.hide_element_style():'',r=d.getElementsByTagName('head')[0];t.setAttribute('id','_vis_opt_path_hides');v&&t.setAttribute('nonce',v.nonce);t.setAttribute('type','text/css');if(t.styleSheet)t.styleSheet.cssText=i;else t.appendChild(d.createTextNode(i));r.appendChild(t)}else{t=d.getElementsByTagName('head')[0];var i=d.createElement('div');i.style.cssText='z-index: 2147483647 !important;position: fixed !important;left: 0 !important;top: 0 !important;width: 100% !important;height: 100% !important;background: white !important;display: block !important;';i.setAttribute('id','_vis_opt_path_hides');i.classList.add('_vis_hide_layer');t.parentNode.insertBefore(i,t.nextSibling)}var o=window._vis_opt_url||d.URL,s='https://dev.visualwebsiteoptimizer.com/j.php?a='+account_id+'&u='+encodeURIComponent(o)+'&vn='+version;if(w.location.search.indexOf('_vwo_xhr')!==-1){this.addScript({src:s})}else{this.load(s+'&x=true')}}};w._vwo_code=code;code.init();})();
  </script>
  <!-- End VWO Async SmartCode -->

    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Understanding Large Language Models</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Merriweather:wght@400;700&family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/atom-one-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"></script>
    <script src="https://unpkg.com/scrollreveal"></script>
    <style>
      :root {
        --primary-color: #3b82f6;
        --secondary-color: #1d4ed8;
        --light-bg: #f9f9f9;
        --dark-bg: #18181b;
        --dark-card: #23272f;
        --dark-border: #374151;
        --dark-text: #f3f4f6;
        --dark-muted: #cbd5e1;
      }
      body {
        font-family: 'Inter', sans-serif;
        background-color: var(--light-bg);
        transition: background-color 0.3s ease;
      }
      body.dark {
        background-color: var(--dark-bg);
        color: var(--dark-text);
      }
      .hero-gradient {
        background: #f9fafb;
      }
      .dark .hero-gradient {
        background: #18181b !important;
      }
      .hero-heading {
        font-family: 'Merriweather', serif;
        font-size: 1.6rem;
        font-weight: 900;
        color: #111827;
        letter-spacing: 0.04em;
        margin-bottom: 1.2rem;
        text-align: center;
        line-height: 1.1;
        text-transform: uppercase;
      }
      @media (min-width: 640px) {
        .hero-heading {
          font-size: 2.2rem;
        }
      }
      .dark .hero-heading {
        color: #fff;
      }
      .hero-subtitle {
        font-size: 1.18rem;
        color: #222;
        font-weight: 400;
        margin-top: 0.5rem;
        margin-bottom: 1.5rem;
        text-align: center;
        letter-spacing: 0.01em;
      }
      .dark .hero-subtitle {
        color: #fff;
      }
      .hero-btn {
        background: linear-gradient(90deg, #2563eb 0%, #6366f1 100%);
        color: #fff;
        padding: 0.65rem 1.5rem;
        border-radius: 9999px;
        font-weight: 600;
        font-size: 1.1rem;
        box-shadow: 0 2px 8px rgba(59,130,246,0.10);
        transition: background 0.2s, transform 0.2s;
        border: none;
        outline: none;
        margin-top: 0.5rem;
      }
      .hero-btn:hover {
        background: linear-gradient(90deg, #1d4ed8 0%, #818cf8 100%);
        transform: translateY(-2px) scale(1.04);
      }
      .dark-mode-toggle {
        position: fixed;
        top: 24px;
        right: 32px;
        background: var(--primary-color);
        color: white;
        border: none;
        padding: 10px 20px;
        border-radius: 25px;
        cursor: pointer;
        box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        transition: all 0.3s ease;
        z-index: 1000;
      }
      .dark-mode-toggle:hover {
        transform: scale(1.05);
      }
      .card {
        transition: transform 0.3s ease, box-shadow 0.3s ease;
      }
      .card:hover {
        transform: translateY(-5px);
        box-shadow: 0 10px 20px rgba(0,0,0,0.1);
      }
      .token-animation {
        animation: tokenPop 0.5s ease;
      }
      @keyframes tokenPop {
        0% { transform: scale(0.8); opacity: 0; }
        100% { transform: scale(1); opacity: 1; }
      }
      .progress-bar {
        position: fixed;
        top: 0;
        left: 0;
        height: 3px;
        background: var(--primary-color);
        transition: width 0.3s ease;
        z-index: 1000;
      }
      .dark .progress-bar {
        background: #60a5fa !important;
      }
      /* NUCLEAR DARK MODE FIX */
      .dark .bg-white,
      .dark .bg-gray-50,
      .dark .bg-gray-100 {
        background: #18181b !important;
      }
      .dark, .dark * {
        color: #f3f4f6 !important;
        border-color: #374151 !important;
      }
      /* Fix analogy/info box text in dark mode */
      .dark .bg-blue-50 { background: #223046 !important; }
      .dark .bg-yellow-50 { background: #3a3622 !important; }
      .dark .bg-purple-50 { background: #2d223a !important; }
      .dark .bg-green-50 { background: #1e3a2a !important; }
      .dark .bg-blue-50, .dark .bg-yellow-50, .dark .bg-purple-50, .dark .bg-green-50 {
        color: #f3f4f6 !important;
      }
      .dark .bg-blue-50 .font-semibold, .dark .bg-blue-50 .text-blue-900 { color: #93c5fd !important; }
      .dark .bg-yellow-50 .font-semibold, .dark .bg-yellow-50 .text-yellow-900 { color: #fde68a !important; }
      .dark .bg-purple-50 .font-semibold, .dark .bg-purple-50 .text-purple-900 { color: #c4b5fd !important; }
      .dark .bg-green-50 .font-semibold, .dark .bg-green-50 .text-green-900 { color: #6ee7b7 !important; }
    </style>
  </head>
  <body class="text-gray-800">
    <div class="progress-bar" id="progressBar"></div>
    <button class="dark-mode-toggle" onclick="toggleDarkMode()">
      <span class="light-icon">ðŸŒž</span>
      <span class="dark-icon hidden">ðŸŒ™</span>
    </button>
    <header class="hero-gradient py-6 sm:py-8 px-4 text-center">
      <div class="max-w-4xl mx-auto">
        <h1 class="hero-heading">Understanding Large Language Models</h1>
        <p class="hero-subtitle">An intuitive guide to how language models work â€” from text to tokens to Transformers</p>
        <div>
          <a href="#section1" class="hero-btn inline-block">Start Learning</a>
        </div>
      </div>
    </header>
    <section class="bg-white py-12 px-4 md:px-12 lg:px-24 border-b">
      <div class="max-w-5xl mx-auto text-center">
        <h2 class="text-2xl font-bold mb-6">Table of Contents</h2>
        <div class="grid gap-4 sm:grid-cols-2 lg:grid-cols-3 text-left">
          <a href="#section1" class="card p-4 rounded-lg border border-gray-200 hover:border-blue-500 hover:shadow transition">
            <h3 class="font-semibold text-blue-700 mb-1">1. What is a Language Model?</h3>
            <p class="text-sm text-gray-600">How language models predict and generate text.</p>
          </a>
          <a href="#section2" class="card p-4 rounded-lg border border-gray-200 hover:border-blue-500 hover:shadow transition">
            <h3 class="font-semibold text-blue-700 mb-1">2. From Text to Tokens</h3>
            <p class="text-sm text-gray-600">How raw text becomes machine-readable tokens.</p>
          </a>
          <a href="#section3" class="card p-4 rounded-lg border border-gray-200 hover:border-blue-500 hover:shadow transition">
            <h3 class="font-semibold text-blue-700 mb-1">3. Recurrent Neural Networks (RNNs)</h3>
            <p class="text-sm text-gray-600">Early models that process sequences step-by-step.</p>
          </a>
          <a href="#section4" class="card p-4 rounded-lg border border-gray-200 hover:border-blue-500 hover:shadow transition">
            <h3 class="font-semibold text-blue-700 mb-1">4. Transformers</h3>
            <p class="text-sm text-gray-600">The breakthrough model architecture behind modern AI.</p>
          </a>
          <a href="#section5" class="card p-4 rounded-lg border border-gray-200 hover:border-blue-500 hover:shadow transition">
            <h3 class="font-semibold text-blue-700 mb-1">5. Large Language Models (LLMs)</h3>
            <p class="text-sm text-gray-600">Scaling up Transformers for incredible capabilities.</p>
          </a>
          <a href="#section6" class="card p-4 rounded-lg border border-gray-200 hover:border-blue-500 hover:shadow transition">
            <h3 class="font-semibold text-blue-700 mb-1">6. Resources</h3>
            <p class="text-sm text-gray-600">Videos, links, and further learning material.</p>
          </a>
        </div>
      </div>
    </section>
    <!-- Section 1 -->
    <section id="section1" class="py-16 px-6 bg-gray-50">
      <div class="max-w-6xl mx-auto">
        <h2 class="text-3xl font-bold mb-6">1. What is a Language Model?</h2>
        <p class="text-lg text-gray-700 leading-relaxed mb-4">
          A language model is a type of machine learning model trained to understand and generate human language. Its main job is to predict the next word in a sentence, based on the words that came before. This prediction power enables a wide range of tasks â€” from autocomplete in your phone, to smart assistants like ChatGPT, to real-time translation services.
        </p>
        <p class="text-lg text-gray-700 leading-relaxed mb-4">
          Instead of understanding language like humans do, language models work statistically. They've seen billions of examples and learn the patterns of how words usually follow one another. This is why they can respond with surprisingly fluent and relevant text â€” even without true understanding.
        </p>
        <div class="border-l-4 border-blue-600 bg-blue-50 p-4 rounded mb-6">
          <p class="font-semibold text-blue-900 mb-1">Analogy</p>
          <p class="text-gray-800">
            Think of it like the game <strong>Mad Libs</strong>. If you say: "The cat sat on the ___,", a language model fills in "mat" â€” not because it knows what a cat is, but because it has seen that phrase thousands of times during training.
          </p>
        </div>
        <p class="text-lg text-gray-700 leading-relaxed">
          Language models are the foundation of modern AI. They're what power chatbots, summarize documents, write code, translate languages, and even help diagnose medical issues â€” all by learning patterns in language.
        </p>
      </div>
    </section>
    <!-- Section 2 -->
    <section id="section2" class="pb-8 px-6 bg-gray-50">  
      <div class="max-w-6xl mx-auto">
        <h2 class="text-3xl font-bold mb-6">2. From Text to Tokens</h2>
        <p class="text-lg text-gray-700 leading-relaxed mb-4">
          Computers can't understand language the way we do â€” they need numbers. So before any language model can learn or make predictions, it first has to convert raw text into something machine-readable: <strong>tokens</strong>.
        </p>
        <p class="text-lg text-gray-700 leading-relaxed mb-4">
          A token is simply a piece of text. It might be a word, part of a word, or even punctuation â€” depending on the tokenization strategy. For example, the sentence:
          <em>"Language models are powerful."</em> could be tokenized into: ["Language", "models", "are", "powerful", "."]
        </p>
        <p class="text-lg text-gray-700 leading-relaxed mb-4">
          Once tokenized, the model assigns each token a unique number, and these numbers are what it actually learns from â€” not the words themselves.
        </p>
        <div class="border-l-4 border-yellow-600 bg-yellow-50 p-4 rounded mb-6">
          <p class="font-semibold text-yellow-900 mb-1">Analogy</p>
          <p class="text-gray-800">
            Imagine a sentence is a basket of groceries. Tokenization is like listing every item in the basket. The model doesn't care about flavors or brands â€” it just needs the list of ingredients to start learning.
          </p>
        </div>
        <p class="text-lg text-gray-700 leading-relaxed mb-6">
          One of the simplest ways to tokenize is the <strong>Bag of Words</strong> model â€” where we ignore order, and just count how many times each word appears. Here's a tiny example:
        </p>
        <pre><code># Sample text documents
  docs = ["I love movies", "Movies are fun", "I love fun"]
  from sklearn.feature_extraction.text import CountVectorizer
  vectorizer = CountVectorizer()
  X = vectorizer.fit_transform(docs)
  print(vectorizer.get_feature_names_out())
  print(X.toarray())</code></pre>
        <p class="text-lg text-gray-700 leading-relaxed mb-4">
          Each document becomes a row in a matrix, and each word becomes a column. The numbers show how often each word appears in each sentence.
        </p>
        <h3 class="text-2xl font-semibold mt-10 mb-4">Try It Yourself</h3>
        <p class="text-gray-700 mb-4">
          Type your own sentence below and see how it gets tokenized:
        </p>
        <input id="inputText" type="text" class="w-full p-3 border border-gray-300 rounded mb-4" placeholder="Type or paste a sentence here...">
        <button onclick="runTokenizer()" class="bg-blue-600 text-white px-4 py-2 rounded hover:bg-blue-700">Tokenize</button>
        <div id="tokenOutput" class="mt-6 text-gray-700 text-base leading-relaxed"></div>
        <p class="mt-8 mb-2 text-base text-black dark:text-white text-center">
          Curious how ChatGPT really sees your text? Try out the actual tokenizer used by OpenAI's models <a href="https://platform.openai.com/tokenizer" target="_blank" rel="noopener" class="underline hover:text-blue-700 dark:hover:text-blue-300">here</a>.
        </p>
      </div>
    </section>
    <script>
      function runTokenizer() {
        const input = document.getElementById('inputText').value.trim();
        if (!input) return;
        const tokens = input.match(/\b\w+\b/g) || [];
        if (window.dataLayer) {
          dataLayer.push({ event: 'tokenizer_used', input_length: input.length, token_count: tokens.length });
        }
        document.getElementById('tokenOutput').innerHTML = `
          <p><strong>Token Count:</strong> ${tokens.length}</p>
          <p><strong>Tokens:</strong></p>
          <div class="bg-gray-100 p-4 rounded mt-2 flex flex-wrap gap-2">
            ${tokens.map(token => `
              <span class="token-animation bg-blue-100 text-blue-800 px-2 py-1 rounded">
                ${token}
              </span>
            `).join('')}
          </div>
        `;
      }
      // Dark mode toggle
      function toggleDarkMode() {
        document.body.classList.toggle('dark');
        const lightIcon = document.querySelector('.light-icon');
        const darkIcon = document.querySelector('.dark-icon');
        lightIcon.classList.toggle('hidden');
        darkIcon.classList.toggle('hidden');
      }
      // Initialize code highlighting
      document.addEventListener('DOMContentLoaded', (event) => {
        document.querySelectorAll('pre code').forEach((block) => {
          hljs.highlightBlock(block);
        });
      });
      // Smooth scroll for anchor links
      document.querySelectorAll('a[href^=\"#\"]').forEach(anchor => {
        anchor.addEventListener('click', function (e) {
          e.preventDefault();
          document.querySelector(this.getAttribute('href')).scrollIntoView({
            behavior: 'smooth'
          });
        });
      });
      // Progress bar
      window.onscroll = function() {
        let winScroll = document.body.scrollTop || document.documentElement.scrollTop;
        let height = document.documentElement.scrollHeight - document.documentElement.clientHeight;
        let scrolled = (winScroll / height) * 100;
        document.getElementById('progressBar').style.width = scrolled + '%';
      };
    </script>
  
  <!-- Section 3 -->
  <section id="section3" class="pb-8 px-6 bg-gray-50">
    <div class="max-w-6xl mx-auto">
      <h2 class="text-3xl font-bold mb-6">3. Recurrent Neural Networks (RNNs)</h2>
  
      <p class="text-lg text-gray-700 leading-relaxed mb-4">
        Language has order. The meaning of a sentence often depends on the words that came before â€” and that's where <strong>Recurrent Neural Networks (RNNs)</strong> come in.
      </p>
  
      <p class="text-lg text-gray-700 leading-relaxed mb-4">
        RNNs are designed to process text <em>one word at a time</em>, keeping a memory of what came before. Think of it like reading a sentence from left to right, storing what you've read so far as you go.
      </p>
  
      <div class="border-l-4 border-blue-600 bg-blue-50 p-4 rounded mb-6">
        <p class="font-semibold text-blue-900 mb-1">Analogy</p>
        <p class="text-gray-800">
          Imagine you're listening to a story one word at a time through a tiny earpiece. You don't get to rewind â€” you just try to remember as much as possible while the words keep coming.
        </p>
      </div>
  
      <p class="text-lg text-gray-700 leading-relaxed mb-4">
        This works well for short sequences, but there's a problem: as the sentence gets longer, RNNs tend to <strong>forget the earlier words</strong>. The memory fades, and the model becomes less accurate over time.
      </p>
  
      <p class="text-lg text-gray-700 leading-relaxed mb-4">
        To fix this, researchers introduced two smarter versions of RNNs:
      </p>
  
      <ul class="list-disc pl-6 text-gray-700 space-y-2 mb-6">
        <li><strong>LSTM (Long Short-Term Memory)</strong>: adds a mechanism that helps the network remember important information for longer and decide what to forget.</li>
        <li><strong>GRU (Gated Recurrent Unit)</strong>: a simpler, faster version of LSTM that still helps with long-term memory.</li>
      </ul>
  
      <p class="text-lg text-gray-700 leading-relaxed">
        These models significantly improved sequence learning, but they still processed words one by one â€” making them slow and limited in how much context they could handle at once. That led to the next breakthrough: the Transformer.
      </p>
    </div>
  </section>

  <!-- Section 4 -->
  <section id="section4" class="pb-8 px-6 bg-gray-50">
    <div class="max-w-6xl mx-auto">
      <h2 class="text-3xl font-bold mb-6">4. Transformers</h2>
  
      <p class="text-lg text-gray-700 leading-relaxed mb-4">
        Transformers completely changed how machines understand language. Unlike RNNs that read one word at a time, Transformers look at the <strong>entire sentence all at once</strong>. This parallel processing makes them faster, more scalable, and more accurate â€” especially for long texts.
      </p>
  
      <p class="text-lg text-gray-700 leading-relaxed mb-4">
        The key idea behind Transformers is <strong>self-attention</strong>. This allows the model to decide which words in a sentence are most relevant to each other â€” regardless of their position.
      </p>
  
      <div class="border-l-4 border-purple-600 bg-purple-50 p-4 rounded mb-6">
        <p class="font-semibold text-purple-900 mb-1">Analogy</p>
        <p class="text-gray-800">
          Imagine reading an entire paragraph and being able to instantly highlight the most important words that explain the meaning of each sentence. That's what self-attention does â€” it lets the model "focus" on what matters.
        </p>
      </div>
  
      <p class="text-lg text-gray-700 leading-relaxed mb-4">
        This architecture is what powers models like BERT, GPT, and even me. It's why Transformers are now the foundation of nearly all modern language AI â€” from search engines to chatbots.
      </p>
  
      <p class="text-lg text-gray-700 leading-relaxed mb-0">
        Transformers are not just faster â€” they're smarter. They can consider every word's relationship to every other word, all at once, which leads to richer understanding and more fluent generation.
      </p>
    </div>
  </section>
  <!-- Section 5 -->
  <section id="section5" class="pb-8 px-6 bg-gray-50">
    
    <div class="max-w-6xl mx-auto">
      <h2 class="text-3xl font-bold mb-6">5. Large Language Models (LLMs)</h2>
  
      <p class="text-lg text-gray-700 leading-relaxed mb-4">
        Large Language Models â€” or LLMs â€” are the next step in the evolution of language AI. They're built on the Transformer architecture, but scaled up dramatically: more data, more parameters, more compute.
      </p>
  
      <p class="text-lg text-gray-700 leading-relaxed mb-4">
        Models like GPT-3.5, GPT-4, Claude, and PaLM have been trained on vast amounts of text from books, websites, and conversations. Because of this, they can write essays, answer questions, generate code, create summaries, hold conversations, and much more.
      </p>
  
      <div class="border-l-4 border-green-600 bg-green-50 p-4 rounded mb-6">
        <p class="font-semibold text-green-900 mb-1">Analogy</p>
        <p class="text-gray-800">
          Imagine giving a student access to the entire internet and letting them read non-stop for years. They won't remember everything exactly, but they'll be able to guess what makes sense in almost any situation.
        </p>
      </div>
  
      <p class="text-lg text-gray-700 leading-relaxed mb-4">
        LLMs don't "think" or "understand" the way humans do â€” they generate the most statistically likely response based on the input they're given. But with enough data and scale, that statistical guesswork starts to feel surprisingly intelligent.
      </p>
  
      <p class="text-lg text-gray-700 leading-relaxed">
        As powerful as they are, LLMs have limitations: they can hallucinate facts, reflect biases in their training data, and can't access real-time information unless specifically designed to. But their capabilities today â€” and potential tomorrow â€” make them one of the most transformative technologies in AI.
      </p>
    </div>
  </section>

  <!-- Section 6 -->
  <section id="section6" class="pb-8 px-6 bg-gray-50">
    
    <div class="max-w-6xl mx-auto">
      <h2 class="text-3xl font-bold mb-6">6. Resources</h2>
      <ul class="list-disc pl-6 space-y-3 text-lg text-gray-700">
        <li><a class="text-blue-600 underline" href="https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi">3Blue1Brown â€“ Deep Learning Playlist</a></li>
        <li><a class="text-blue-600 underline" href="https://huggingface.co/learn">Hugging Face Learning Hub</a></li>
        <li><a class="text-blue-600 underline" href="https://jalammar.github.io/illustrated-transformer/">The Illustrated Transformer by Jay Alammar</a></li>
      </ul>
    </div>
  </section>

  <footer class="text-center text-sm text-gray-500 py-6 border-t mt-10">
    Â© 2025 Understanding LLMs. Built with care.
  </footer>

  <script>
    // Initialize ScrollReveal
    ScrollReveal().reveal('.card', {
      delay: 200,
      distance: '20px',
      duration: 1000,
      easing: 'cubic-bezier(0.5, 0, 0, 1)',
      origin: 'bottom'
    });

    // Progress bar
    window.onscroll = function() {
      let winScroll = document.body.scrollTop || document.documentElement.scrollTop;
      let height = document.documentElement.scrollHeight - document.documentElement.clientHeight;
      let scrolled = (winScroll / height) * 100;
      document.getElementById('progressBar').style.width = scrolled + '%';
    };

    // Dark mode toggle
    function toggleDarkMode() {
      document.body.classList.toggle('dark');
      const lightIcon = document.querySelector('.light-icon');
      const darkIcon = document.querySelector('.dark-icon');
      lightIcon.classList.toggle('hidden');
      darkIcon.classList.toggle('hidden');
    }

    // Initialize code highlighting
    document.addEventListener('DOMContentLoaded', (event) => {
      document.querySelectorAll('pre code').forEach((block) => {
        hljs.highlightBlock(block);
      });
    });

    // Smooth scroll for anchor links
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener('click', function (e) {
        e.preventDefault();
        document.querySelector(this.getAttribute('href')).scrollIntoView({
          behavior: 'smooth'
        });
      });
    });
  </script>
</body>
</html>
